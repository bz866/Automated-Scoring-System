{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utlis import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import string\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _cleanText(t):\n",
    "    '''\n",
    "    t string, raw text input\n",
    "    ret t string, a list of words\n",
    "    '''\n",
    "    t = t.lower()\n",
    "    t = re.sub(r'[^\\w\\s]','',t)\n",
    "    t = re.sub(r'\\s*(\\(\\d)|(\\))\\s*', '', t)\n",
    "    #t = t.split()\n",
    "    return t\n",
    "\n",
    "def _nltktag(text):\n",
    "    \"\"\"\n",
    "    Using nltk.word_tokenize to tag words as 'NN', 'DT'\n",
    "    for extracting noun, verb, adj\n",
    "    \"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    tagged_words = pos_tag(words)\n",
    "    return tagged_words\n",
    "\n",
    "def _wordCount(text):\n",
    "    \"\"\"\n",
    "    input: string \n",
    "    output: int -- Count of words\n",
    "    \"\"\"\n",
    "    return sum(Counter(text.split()).values())\n",
    "\n",
    "def _longWordCount(text):\n",
    "    \"\"\"\n",
    "    input: string\n",
    "    output: int -- Count of Long words\n",
    "    \n",
    "    \"\"\"\n",
    "    #Average word length without stop words is 5.6\n",
    "    ##threshold = 6\n",
    "    long_words = [word for word in text.split() if len(word)>6]\n",
    "    return sum(Counter(long_words).values())\n",
    "\n",
    "def _partOfSpeechCount(text):\n",
    "    \n",
    "    tagged_words = _nltktag(text)\n",
    "    #Noun Count\n",
    "    listnn = [w[0] for w in tagged_words if w[1] in ['NN', 'NNP', 'NNPS','NNS']]\n",
    "    nnCount = sum(Counter(listnn).values())\n",
    "    #Verb Count\n",
    "    listvb = [w[0] for w in tagged_words if w[1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]\n",
    "    verbCount = sum(Counter(listvb).values())\n",
    "    #Adjective Count\n",
    "    listadj = [w[0] for w in tagged_words if w[1] in ['JJ', 'JJR', 'JJS']]\n",
    "    adjCount = sum(Counter(listadj).values())\n",
    "    #Adverb Count\n",
    "    listadvb = [w[0] for w in tagged_words if w[1] in ['RR', 'RBR', 'RBS']]\n",
    "    advbCount = sum(Counter(listadvb).values())\n",
    "    return nnCount, verbCount, adjCount, advbCount\n",
    "\n",
    "def _commaCount(text):\n",
    "    return text.count(',')\n",
    "\n",
    "def _punctuationCount(text):\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "    return count(text,set(string.punctuation)) \n",
    "\n",
    "def _sentenceCount(text):\n",
    "    return len(nltk.sent_tokenize(text))\n",
    "\n",
    "def _wordLengthAvg(text):\n",
    "    l = text.split()\n",
    "    return sum(map(len, l))/float(len(l))\n",
    "\n",
    "\n",
    "\n",
    "def _spellingError(text):\n",
    "    \"\"\"\n",
    "    return: Count of misspelled words\n",
    "    \"\"\"\n",
    "    my_dict = enchant.Dict(\"en_US\")\n",
    "    my_checker = SpellChecker(my_dict)\n",
    "    my_checker.set_text(text)\n",
    "    return len([error.word for error in my_checker])\n",
    "\n",
    "def _lexicalDiversity(t):\n",
    "    \"\"\"\n",
    "    t input seq, String\n",
    "    ---------\n",
    "    return float ratio\n",
    "    \"\"\"\n",
    "    return len(set(t)) / len(t)\n",
    "\n",
    "def _quotationMark(t):\n",
    "    '''\n",
    "    t string, raw input\n",
    "    ret li, ceil of pairs of quatation contained in input text\n",
    "    '''\n",
    "    li = re.findall('\"',t)\n",
    "    n = len(li)\n",
    "    n = int(np.ceil(n/2))\n",
    "    return n\n",
    "    \n",
    "def _exclamationMarks(text):\n",
    "    return text.count('!')\n",
    "\n",
    "def _featureExtraction(text):\n",
    "    \"\"\"\n",
    "    input: essay as a long string\n",
    "    \n",
    "    output:feature vector\n",
    "    elements in output: \n",
    "    1. word count \n",
    "    2. long word count\n",
    "    3. noun word count\n",
    "    4. verb count\n",
    "    5. comma count\n",
    "    6. punctuation count\n",
    "    7. sentence count\n",
    "    8. adjective count\n",
    "    9. adverb count\n",
    "    10. lexical diversity\n",
    "    11. quatation mark\n",
    "    12. word length\n",
    "    13. spelling error\n",
    "    14*.bracket count\n",
    "    15*.exclamation count\n",
    "    16*. Foreign words count\n",
    "    \"\"\"\n",
    "    wordCount = _wordCount(text)\n",
    "    longWordCount = _longWordCount(text)\n",
    "    nounCount, verbCount, adjCount, advbCount = _partOfSpeechCount(text)\n",
    "    commaCount = _commaCount(text)\n",
    "    puncCount = _punctuationCount(text)\n",
    "    sentCount = _sentenceCount(text)\n",
    "    lexDiv = _lexicalDiversity(text)\n",
    "    quatMarkCount = _quotationMark(text)\n",
    "    avgWordLen = _wordLengthAvg(text)\n",
    "    spelErrorCount = _spellingError(text)\n",
    "    #brcktCount = _br\n",
    "    exclamationCount = _exclamationMarks(text)\n",
    "    \n",
    "    f = np.array([wordCount, longWordCount, nounCount, verbCount, commaCount, puncCount, sentCount, \n",
    "                 adjCount, advbCount, lexDiv, quatMarkCount, avgWordLen, spelErrorCount])\n",
    "    \n",
    "    f_res = _addedByStep(f)\n",
    "    \n",
    "    return f_res #feature vector\n",
    "\n",
    "def _addedByStep(vec):\n",
    "    \"\"\"\n",
    "    input: vec\n",
    "    output: vector that added up at each element\n",
    "    \"\"\"\n",
    "    return [sum(vec[0:i+1]) for i in range(0,len(vec))] \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   final_score  \n",
       "0          8.0  \n",
       "1          9.0  \n",
       "2          7.0  \n",
       "3         10.0  \n",
       "4          8.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read training data\n",
    "training_ori = pd.read_excel(\"./training_set_rel3.xlsx\", sheetname=\"training_set\", header=0)\n",
    "training = pd.read_csv(\"./training_final.csv\", sep=',',header=0, index_col=0)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1783 essays in Topic 1.\n",
      "1800 essays in Topic 2.\n",
      "1726 essays in Topic 3.\n",
      "1772 essays in Topic 4.\n",
      "1805 essays in Topic 5.\n",
      "1800 essays in Topic 6.\n",
      "1569 essays in Topic 7.\n",
      "723 essays in Topic 8.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,9):\n",
    "    print(\"{} essays in Topic {}.\".format(training[training['essay_set']==i].shape[0], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate feature vector for all essays\n",
    "start = time.time()\n",
    "training['f_vec'] = [_featureExtraction(essay) for essay in training['essay']]\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/twff/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1_training = training[training['essay_set']==1]\n",
    "t2_training = training[training['essay_set']==2]\n",
    "t3_training = training[training['essay_set']==3]\n",
    "t4_training = training[training['essay_set']==4]\n",
    "t5_training = training[training['essay_set']==5]\n",
    "t6_training = training[training['essay_set']==6]\n",
    "t7_training = training[training['essay_set']==7]\n",
    "t8_training = training[training['essay_set']==8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-fold cross validation for Topic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-dfd72799cebf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcohen_kappa_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkappa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skll'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from skll.metrics import kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't1_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f06678cd405c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1_training\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'f_vec'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1_training\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'final_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mregr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't1_training' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(list(t1_training['f_vec']),list(t1_training['final_score']), test_size=0.2)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred = [round(y) for y in y_pred]\n",
    "kappa(y_test, y_pred, weights='quadratic', allow_off_by_one=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics.scorer import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kappa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1737f088bf3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkappa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'quadratic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_off_by_one\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kappa' is not defined"
     ]
    }
   ],
   "source": [
    "scoring = make_scorer(kappa, weights='quadratic', allow_off_by_one=False)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVR(C=1))\n",
    "cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVR(C=1))\n",
    "cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79873638,  0.71606179,  0.75596735,  0.73723823,  0.78399106])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), RandomForestRegressor(max_depth=2, random_state=0))\n",
    "cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8278806 ,  0.75744681,  0.80544973,  0.815279  ,  0.79057534])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), AdaBoostRegressor())\n",
    "cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83316016,  0.75574183,  0.8036342 ,  0.79862869,  0.80290169])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), MLPRegressor())\n",
    "cross_val_score(clf, X_train, y_train, cv=cv,scoring = scoring)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
